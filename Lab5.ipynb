{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadavschwalb/image_processing/blob/main/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlWn-wJRsWIo",
        "nbpresent": {
          "id": "a8a91dc7-090e-4553-8fd8-34d2f4588f4e"
        }
      },
      "source": [
        "# Lab 5 - Image Restoration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQTZE-mcsWIp",
        "nbpresent": {
          "id": "1c0b3f48-22a6-401e-b2e1-37a21ddf5ef8"
        }
      },
      "source": [
        "## Goal: Introduction to image restoration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XiSn304jgCU"
      },
      "source": [
        "## ---  Make sure you are using GPU accelerator in Colab Runtime  ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5Ki4tAsWIs",
        "nbpresent": {
          "id": "3cbfea80-b8b2-4a8f-b7d8-f19b42dc2e42"
        }
      },
      "source": [
        "Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSDTGrAXsWIt",
        "nbpresent": {
          "id": "da9c5657-97c4-41da-a658-29db455698af"
        }
      },
      "source": [
        "%matplotlib inline \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform,io,util,img_as_float\n",
        "from skimage import restoration\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNr3nbTRIBvw"
      },
      "source": [
        "Mount to your drive to open files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og8zfX7aIMP0"
      },
      "source": [
        "#Mount:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd 'path to your folder in drive'\n",
        "!ls # (print the files and folders in the crrent folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLemwpNYvARJ"
      },
      "source": [
        "Insert your implementaion - add blurring and noise to image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qxslYAaGz27"
      },
      "source": [
        "# The function return two images: a blurred image \n",
        "# and an image after blurring and noise adding\n",
        "def AddBlurreAndNoise(img, filter_blur):\n",
        "    # Insert your implementaion here\n",
        "\n",
        "    return img_blurre, img_blurre_noise\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ohy9q1IwN_"
      },
      "source": [
        "Load image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZgUQKansWI4",
        "nbpresent": {
          "id": "9b2784d6-9892-4598-8129-131052c0fe39"
        }
      },
      "source": [
        "img = io.imread('lena.gif')\n",
        "img = img_as_float(img)\n",
        "print (\"Image shape:{}, Image data type:{}\".format(img.shape,img.dtype))\n",
        "# Use gaussian kernel for burring the image\n",
        "# gaussian kernel is separable function\n",
        "filter_blur = cv2.getGaussianKernel(ksize=5,sigma=1.85)*cv2.getGaussianKernel(ksize=5,sigma=1.85).T \n",
        "\n",
        "blurred, noise = AddBlurreAndNoise(img,filter_blur)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(131),plt.imshow(img, cmap='gray'),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(132),plt.imshow(blurred, cmap='gray'),plt.title('Blurred')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(133),plt.imshow(noise, cmap='gray'),plt.title('Blurred + Noised')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdyDlQ4UsWI-",
        "nbpresent": {
          "id": "36cefb1b-be77-4acf-be49-3aff9ea47e88"
        }
      },
      "source": [
        "###  Part 1 - Inverse Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7mbHTHksWJA"
      },
      "source": [
        "1. Test the restoration with the Inverse Filter for deblurring and denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3XjA8PMsWJC",
        "nbpresent": {
          "id": "da01d3f3-7dab-4582-9c5f-2e1b590d418e"
        }
      },
      "source": [
        "def InverseFilter(noise_img,filter_blur):\n",
        "    # Paste your implementaion of Inverse Filter here\n",
        "\n",
        "    return denoise_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIjUGewssWJF"
      },
      "source": [
        "denoise_Invert_img = InverseFilter(noise,filter_blur)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(131),plt.imshow(img, cmap='gray'),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(132),plt.imshow(noise, cmap='gray'),plt.title('Blurred + Noised')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(133),plt.imshow(denoise_Invert_img, cmap='gray'),plt.title('After Invert Filter')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53WiJ5lLsWJL"
      },
      "source": [
        "2. What is the problem with the Inverse Filter? How can this be solved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXkECpoQGz3P"
      },
      "source": [
        "```\n",
        "# Insert your answer here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxhdllqpsWJP"
      },
      "source": [
        "### Part 2 - Pseudo Inverse Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8t3rlazsWJS"
      },
      "source": [
        "1. Test the restoration with the Pseudo Inverse Filter for deblurring and denoising."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-v1mQXMsWJU"
      },
      "source": [
        "def PseudoInverseFilter(noise_img, filter_blur, epsilon=0.5):\n",
        "    # Paste your implementaion of Pseudo Inverse Filter here\n",
        "\n",
        "    return denoise_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPzIbGhxsWJY"
      },
      "source": [
        "denoise_pseudo_img = PseudoInverseFilter(noise,filter_blur)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(131),plt.imshow(img, cmap='gray'),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(132),plt.imshow(noise, cmap='gray'),plt.title('Blurred + Noised')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(133),plt.imshow(denoise_pseudo_img, cmap='gray'),plt.title('After Pseudo Invert Filter')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zzMu_xusWJe"
      },
      "source": [
        "The Root Mean Square (RMS) error of restoration is defined in the following way:\n",
        "\\begin{equation*}\n",
        "RMS = \\left( \\frac{1}{MN}  \\sum_{k=0}^{M-1} \\sum_{k=0}^{N-1} (\\hat{f}(i,j)-f(i,j))^2 \\right)^{0.5}\n",
        "\\end{equation*}\n",
        "\n",
        "where $f(i, j)$ is the original image, $\\hat{f}(i,j)$ is the restored image and $M \\times N$ is the size of both images. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLkOgUX2sWJf"
      },
      "source": [
        "2. Plot the graph of the RMS error (Y axis) versus the parameter $\\epsilon$(X axis) . Use several values in the range 0-1\n",
        "\n",
        "(the variance of the noise $\\sigma _n ^2$ is fixed to the default value in the supplied program).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inmgRCGMsWJg"
      },
      "source": [
        "# Insert your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6daxis4WRzx5"
      },
      "source": [
        "__Show the result of the best restoration by the best epsilon value.__ (if it different than the previous shown result)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82JSp-6jRzKJ"
      },
      "source": [
        "# Insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SUMVVOMsWJj"
      },
      "source": [
        "3.Now fix the parameter $\\epsilon = 0.5$.\n",
        "Plot the graph of the Root Mean Square (RMS) error of restoration (Y axis) versus the\n",
        "variance of the noise $\\sigma_n^2$ (X axis).\n",
        "__And Show the result of the best restoration__\n",
        "(Use several values in the range 0-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRxBDwkBsWJm"
      },
      "source": [
        "# Insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utfzwk0bsWJu"
      },
      "source": [
        "   3.1. For what maximal value of the variance of the noise you still get an acceptable restoration? **show the noisy and result plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFQ1zJ5yGz3h"
      },
      "source": [
        "```\n",
        "# Insert your answer here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNjYZeNDsWJy"
      },
      "source": [
        "### Part 3 - Wiener Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ymOt67csWJ0"
      },
      "source": [
        "1. Test the restoration with the Wiener Filter for deblurring and denoising\n",
        "\n",
        "Assume that the variance used in the Wiener filter formula is equal to the variance of the noise $\\sigma_n^2$\n",
        ", and both of them are equal to 0.01 (for image in a range of 0-1) or 0.01 âˆ— 255\n",
        "(for image in a range of 0-255)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSWHvrBsWJ1"
      },
      "source": [
        "def WienerFilter(noise_img,filter_blur,sigma=0.01, alpha=0.095):\n",
        "    # Paste your implementaion of Wiener Filter here\n",
        "\n",
        "    return denoise_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDl9OeJsWJ4"
      },
      "source": [
        "denoise_wiener_img = WienerFilter(noise,filter_blur)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(131),plt.imshow(img, cmap='gray'),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(132),plt.imshow(noise, cmap='gray'),plt.title('Blurre + Noise')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(133),plt.imshow(denoise_wiener_img, cmap='gray'),plt.title('After Wiener Filter')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7AmuDrlGz3r"
      },
      "source": [
        "2. Plot the graph of the Root Mean Square (RMS) error of restoration (Y axis) versus the parameter $\\sigma_n^2$ (X axis) (change $\\sigma_n$ only in the filter, the noise image stay the same, also no need to change alpha). __Show the result of the best restoration.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiaRA-6WGz3s"
      },
      "source": [
        "# Insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jha4bTnsWKH"
      },
      "source": [
        "### Part 4 - Deep learning (DnCNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEyQccZHsWKI"
      },
      "source": [
        "1. After using a few filters to restoration the image, Lets try with the new approach **Deep learning** and compare the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_qkPAmCsWKK"
      },
      "source": [
        "For building the neural network we will use the [PyTorch framwork](https://pytorch.org/) \n",
        "\n",
        "Because of lack of time we aren't going to train the network here.\n",
        "We will use a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcY7sq2DsWKL"
      },
      "source": [
        "Few more imports for using pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pc6pQ7ZsWKL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKsU2q17sWKP"
      },
      "source": [
        "Now we will define the architecture of the neural network.\n",
        "\n",
        "We will implement the [DnCNN](http://www4.comp.polyu.edu.hk/~cslzhang/paper/DnCNN.pdf) architecture:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKL3hfMisWKQ"
      },
      "source": [
        "![DnCNN architecture](https://raw.github.com/cszn/DnCNN/master/figs/dncnn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9swhEVBsWKS"
      },
      "source": [
        "Has you can see the architecture is a class that inherit from nn.Module (pytorch module) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPanWArsWKT"
      },
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, channels, num_of_layers=17):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        # first layer: conv2d -> Relu (for activation) :\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        # then lets defined all the other hidden layer as: conv2d -> BatchNorm -> Relu\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        # and at the end: need to get back the image so conv2d with out_channels as in the original image:\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        # insert all the layers in to Sequential that will pass the data in order\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # defined the forward pass of our network\n",
        "        out = self.dncnn(x)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G1iPBqMGz38"
      },
      "source": [
        "lets pay attention that we don't need to defined the back propagation as the the Pytorch framework will do it for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpLwoCnyZQtf"
      },
      "source": [
        "2. What is the *Conv* in the network architecture? Give a brief explanation (up to 4 lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A_pw2p4ZaGX"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Insert your answer here\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-VGoQDbGz38"
      },
      "source": [
        "After build the network architecture we need to load the pretrained model and insert the noisy image to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-EMD4ARsWKV"
      },
      "source": [
        "def DnCNN_network(noise_img, num_of_layers=17, model_path='net.pth'):\n",
        "    \n",
        "    print('Loading model ...')\n",
        "    # defined the network, use the class we create above\n",
        "    net = DnCNN(channels=1, num_of_layers=num_of_layers)\n",
        "    traind_model = nn.DataParallel(net)\n",
        "    # load pretrain model\n",
        "    pretraind = torch.load(model_path)\n",
        "    # get the state of the model (weights + baises ...)\n",
        "    traind_model.load_state_dict(pretraind)\n",
        "    traind_model.double()\n",
        "    # say to pytorch that we juist want to test the model (not tarin it)\n",
        "    traind_model.eval()\n",
        "    print('Loaded\\n')\n",
        "    # Expend dim for using the network:\n",
        "    noise_img = np.expand_dims(noise_img, 0) # batch dim\n",
        "    noise_img = np.expand_dims(noise_img, 1) # channels dim\n",
        "    # cast to tensor variable \n",
        "    noise_img = torch.DoubleTensor(noise_img)\n",
        "    INoisy = Variable(noise_img)\n",
        "    \n",
        "    with torch.no_grad(): # this can save much memory\n",
        "        print(\"Inserting the noisy image...\\n\")\n",
        "        the_noise_that_we_learned = traind_model(INoisy)\n",
        "        plt.imshow(the_noise_that_we_learned.cpu().squeeze(), cmap='gray'),plt.title('The noise that the network predict')\n",
        "        plt.show()\n",
        "        Out = torch.clamp(INoisy.cpu() - the_noise_that_we_learned.cpu(), 0., 1.)\n",
        "    return Out.squeeze()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thCSKdj3Gz4A"
      },
      "source": [
        "3. Explain the following line in the code. Why do we need this line? \n",
        "\n",
        "*Out = torch.clamp(INoisy.cpu() - the_noise_that_we_learned.cpu(), 0., 1.)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDqux2kkGz4B"
      },
      "source": [
        "```\n",
        "# Insert your answer here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_JlLz_DGz4B"
      },
      "source": [
        "Now lets use the neural network and show the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKQXG-GysWKb"
      },
      "source": [
        "denoise_dncnn_img = DnCNN_network(noise)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(131),plt.imshow(img, cmap='gray'),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(132),plt.imshow(noise, cmap='gray'),plt.title('Blurre + Noise')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(133),plt.imshow(denoise_dncnn_img, cmap='gray'),plt.title('After substract the noise that learned')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7k9-7DWGz4F"
      },
      "source": [
        "4. Lets compare the results from all the methods that we used in this lab:\n",
        "\n",
        "   Show the best image after restoration from all the methods (Pseudo Invert Filter, Wiener Filter, DnCNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9yLncfQsWKh"
      },
      "source": [
        "# Insert your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}