{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_Student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadavschwalb/image_processing/blob/main/Lab3_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-eUi1BBqQ8V"
      },
      "source": [
        "# **Lab 3 – Quantization and Color Histogram Equalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ8rq4q_s_0m"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Zu_Qa4tDKS"
      },
      "source": [
        "# change working directory and verify files are accessible\n",
        "%cd '/content/drive/My Drive/'\n",
        "%ls -l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edyUi1_tqQ8a"
      },
      "source": [
        "**Import the necessary libraries for Lab 3:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ol5aFVfqQ8X"
      },
      "source": [
        "%matplotlib inline \n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pylab as plt\n",
        "from skimage import transform,io\n",
        "from sklearn import cluster\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgEedrFZ4XCk"
      },
      "source": [
        "# Part 1: Quantization\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqPlm8Nl4XCl"
      },
      "source": [
        "1. Insert your function quant_img(img, N) from the preliminary report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyXpTZ1I4XCl"
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmi1qNDG4XCp"
      },
      "source": [
        "2. Load the image of your choise as gray scale image and perform uniform quantization on your image to **2, 4, 8, 16, 32 and 64** gray levels.   \n",
        "    From which quantization factor do you observe the problem of **false contours**? Attach relevant examples from the quantized images to demonstrate your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XB9JlzR4XCp",
        "scrolled": true
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHRuU2lb4XCr"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBpYOOpQ4XCs"
      },
      "source": [
        "3. Use the supplied function *imnoise()*, that adds Gaussian noise, on the image before quantization and test the effect on the false contours problem. Use zero mean noise with several values of variance.   \n",
        "    You can use the quantization level that you chose in the previous section.\n",
        "    \n",
        "    What value of variance yields the optimal result? Attach examples of the quantized images with optimal and non-optimal variance values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_B-uw7h4XCs"
      },
      "source": [
        "def imnoise(img, mean, std):\n",
        "    noisy_img = img + np.random.normal(mean, std, img.shape)\n",
        "    return np.clip(noisy_img, 0, 255)  # keep the bounds "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYSTcPPl4XCv"
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMHzUJkN52dh"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzCD_9k14XCx"
      },
      "source": [
        "4. perform quantization on your image using K-means to **2, 4, 8, 16, 32 and 64** gray levels. You may use the provided function. Plot the resulting histograms of both methods. What is the main difference?\n",
        "    Compare your results to the results from the previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOORc9ErpSbT"
      },
      "source": [
        "def kmeans_quant_img(img,N):\n",
        "    m,n = img.shape\n",
        "    np.random.seed(0)\n",
        "    image_array = img.reshape(-1,1)\n",
        "    image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
        "    kmeans = cluster.KMeans(n_clusters= N).fit(image_array_sample)   \n",
        "    labels = kmeans.predict(image_array)\n",
        "    q_img = np.zeros_like(img)\n",
        "    label_idx = 0\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            q_img[i][j] = kmeans.cluster_centers_[labels[label_idx]]\n",
        "            label_idx += 1\n",
        "\n",
        "    return q_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ptncyzd4XCx",
        "scrolled": true
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo2VOuqX4XCz"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nciDZ1VT4XCz"
      },
      "source": [
        "# Part 2: Color Histogram Equalization\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr3Z7zNt4XCz"
      },
      "source": [
        "Use the supplied function hist_demo().  \n",
        "* Observe the following demonstrations:\n",
        "  * Contrast stretching.\n",
        "  * Histogram equalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKKZyd-54XC0"
      },
      "source": [
        "def hist_demo(img):\n",
        "    # Contrast stretching\n",
        "    img_dbl = np.float64(img)\n",
        "    min_im = np.min(np.min(img_dbl))\n",
        "    max_im = np.max(np.max(img_dbl))\n",
        "    img_stretched_contrast = np.uint8(255*(img_dbl-min_im)/(max_im-min_im))\n",
        "    \n",
        "    # Histogram equalization\n",
        "    img_hist_eq = cv2.equalizeHist(img) \n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "    ax = axes.ravel()\n",
        "    ax[0].imshow(img, cmap='gray')\n",
        "    ax[0].set_title(\"Original image\")\n",
        "    hist = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    ax[1].plot(hist)\n",
        "    ax[1].set_title(\"Original image histogram\")  \n",
        "    plt.tight_layout(); plt.show()\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "    ax = axes.ravel()\n",
        "    ax[0].imshow(img_stretched_contrast, cmap='gray')\n",
        "    ax[0].set_title(\"Contrast stretching image\")\n",
        "    hist = cv2.calcHist([img_stretched_contrast],[0],None,[256],[0,256])\n",
        "    ax[1].plot(hist)\n",
        "    ax[1].set_title(\"Contrast stretching histogram\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "    ax = axes.ravel()\n",
        "    ax[0].imshow(img_hist_eq, cmap='gray')\n",
        "    ax[0].set_title(\"Histogram equalization image\")\n",
        "    hist = cv2.calcHist([img_hist_eq],[0],None,[256],[0,256])\n",
        "    ax[1].plot(hist)\n",
        "    ax[1].set_title(\"Histogram equalization histogram\")\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV-BH8YE4XC1"
      },
      "source": [
        "1. Load a **gray image** of your choise ans test these demonstrations. Make sure that the image you choose is indeed affected by both operations.   \n",
        "    On which images contrast stretching won’t affect?  On which images histogram equalization won’t affect?\n",
        "    \n",
        "    Note: \n",
        "    If you are experiencing any errors, try to convert the image to uint8 with image_as_ubyte (as we did in the first lab) before using the suplied function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7VhnLoz4XC1",
        "scrolled": true
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yze5aGz94XC3"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK9ZkBxY4XC3"
      },
      "source": [
        "**Color Histogram Equalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgYaX3fT4XC4"
      },
      "source": [
        "2. We now expand Historgram Equalization to color images (RGB).\n",
        "Write a new function ***hist_eq_rbg(img)*** which performs Histogram Equalization on an RGB image, equalizing each one of its color channels independently (Hint: use the given 1D function demonstrated above). Apply your function on your color image and display the results. Display also the initial and modified channelwise histograms. Are the original colors preserved? Explain.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFwiFMYk4XC5"
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxk0qlNP6ICA"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf0SuyNt4XC6"
      },
      "source": [
        "3. Suggest another approach, which would enable preserving the image colors. (Hint: consider converting to a different color space. Is there a color space, in which the color histogram equalization can be reduced to a 1D problem?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wldcbb81t5HB"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWAkrlmy4XC7"
      },
      "source": [
        "4. Implement your approach in a new function called ***hist_eq_color*** and apply it on your color image. Display the modified image. Are the results better? (Remember to convert your image back to RGB when comparing). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAG1Wllc4XC7"
      },
      "source": [
        "# Insert your code:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYzzqtyb6Qjw"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjnFdUHn1D6S"
      },
      "source": [
        "# Part 3: Camshift Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVajyjp_6UJl"
      },
      "source": [
        "1. We now test the Camshift algorithm for video tracking, as explained in the Lab Manual. Given is a demo script, which loads a short video file 'MOT16-04-trimmed.mp4' from the MOT16 dataset and writes a new video file 'output.mp4' displaying the tracked object. Modify the initial ROI coordinates so that the algorithm tracks an object to your liking and observe the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0mfDRq875vb"
      },
      "source": [
        "2. Attach several captured frames of the tracked object to your report and answer the following: \n",
        "* What color space is used here for tracking and why? \n",
        "* What is the main disadvantage of the given algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sz7aQ5OrZ4L"
      },
      "source": [
        "Write your answer here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2AWllbA1QM_"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture('MOT16-04-trimmed.mp4')\n",
        "\n",
        "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
        "# We convert the resolutions from float to integer.\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "out = cv2.VideoWriter('output.mp4',cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width,frame_height))\n",
        "\n",
        "# take first frame of the video\n",
        "ret,frame = cap.read()\n",
        "\n",
        "# setup initial location of window\n",
        "#### INSERT THE ROI VALUES HERE ###\n",
        "x,h,y,w = 0, 0, 0, 0 \n",
        "track_window = (x,y,w,h)\n",
        "\n",
        "# set up the ROI for tracking\n",
        "roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "# convert ROI to HSV\n",
        "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# create ROI normalized histogram\n",
        "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
        "\n",
        "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
        "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "while(1):\n",
        "    ret ,frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # convert frame to HSV\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # get probabilty map\n",
        "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "        # apply meanshift to get the new location\n",
        "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
        "        \n",
        "        # draw window on frame\n",
        "        pts = cv2.boxPoints(ret)\n",
        "        pts = np.int0(pts)\n",
        "        img2 = cv2.polylines(frame,[pts],True, 255,2)\n",
        "        k = cv2.waitKey(60) & 0xff\n",
        "        \n",
        "        if k == 27:\n",
        "            break\n",
        "        else:\n",
        "            # Write the frame into the file 'output.avi'\n",
        "            out.write(img2)\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}